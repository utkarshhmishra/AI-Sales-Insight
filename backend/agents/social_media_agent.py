"""
Social Media Agent
Monitors and analyzes social media presence and sentiment
"""

import asyncio
from typing import Dict, Any, List
import time
from datetime import datetime, timedelta
import random

from agents.base_agent import BaseAgent, AgentInput, AgentOutput
import logging

logger = logging.getLogger(__name__)


class SocialMediaAgent(BaseAgent):
    """Agent for monitoring social media presence and sentiment"""
    
    def __init__(self):
        super().__init__(
            name="SocialMediaAgent",
            description="Tracks LinkedIn, Twitter/X activity and engagement metrics"
        )
    
    async def execute(self, input_data: AgentInput) -> AgentOutput:
        """Execute social media monitoring"""
        start_time = time.time()
        
        try:
            await self.validate_input(input_data)
            
            self.logger.info(f"Monitoring social media for {input_data.company_name}")
            
            # Collect social media data
            linkedin_data = await self._fetch_linkedin_data(input_data.company_name)
            twitter_data = await self._fetch_twitter_data(input_data.company_name)
            sentiment_analysis = await self._analyze_sentiment(input_data.company_name)
            
            # Compile data
            data = {
                "linkedin": linkedin_data,
                "twitter": twitter_data,
                "sentiment": sentiment_analysis,
                "last_updated": datetime.now().isoformat()
            }
            
            # Generate insights
            insights = self._generate_insights(data)
            
            execution_time = int((time.time() - start_time) * 1000)
            
            output = self._create_output(
                status="success",
                data=data,
                insights=insights,
                confidence_score=0.75,
                execution_time_ms=execution_time
            )
            
            self.log_execution(input_data, output)
            return output
            
        except Exception as e:
            execution_time = int((time.time() - start_time) * 1000)
            self.logger.error(f"Error in SocialMediaAgent: {str(e)}")
            
            return self._create_output(
                status="error",
                data={},
                insights=[],
                confidence_score=0.0,
                execution_time_ms=execution_time,
                error_message=str(e)
            )
    
    async def _fetch_linkedin_data(self, company_name: str) -> Dict[str, Any]:
        """Fetch LinkedIn company data"""
        await asyncio.sleep(0.6)
        
        # In production: Use LinkedIn API or scraping
        return {
            "company_page": {
                "followers": random.randint(15000, 50000),
                "employees_on_linkedin": random.randint(400, 800),
                "recent_posts": [
                    {
                        "date": (datetime.now() - timedelta(days=2)).isoformat(),
                        "content": "Excited to announce our expansion into Southeast Asia! ğŸš€",
                        "likes": 245,
                        "comments": 32,
                        "shares": 18
                    },
                    {
                        "date": (datetime.now() - timedelta(days=5)).isoformat(),
                        "content": "New product launch: AI-powered analytics platform now live!",
                        "likes": 312,
                        "comments": 45,
                        "shares": 28
                    },
                    {
                        "date": (datetime.now() - timedelta(days=9)).isoformat(),
                        "content": "We're hiring! Join our growing team in Bangalore and Hyderabad.",
                        "likes": 189,
                        "comments": 67,
                        "shares": 41
                    }
                ]
            },
            "engagement_metrics": {
                "average_likes_per_post": 248,
                "average_comments_per_post": 48,
                "posting_frequency": "3-4 times per week",
                "engagement_rate": "4.2%"
            },
            "hiring_activity": {
                "open_positions": 45,
                "top_roles": ["Software Engineer", "Sales Executive", "Product Manager"],
                "growth_indicator": "High - 45 active job postings"
            }
        }
    
    async def _fetch_twitter_data(self, company_name: str) -> Dict[str, Any]:
        """Fetch Twitter/X data"""
        await asyncio.sleep(0.5)
        
        # In production: Use Twitter API v2
        return {
            "profile": {
                "handle": f"@{company_name.replace(' ', '').lower()}",
                "followers": random.randint(8000, 25000),
                "following": random.randint(500, 1500),
                "tweets": random.randint(2000, 5000),
                "verified": True
            },
            "recent_tweets": [
                {
                    "date": (datetime.now() - timedelta(days=1)).isoformat(),
                    "content": "Big announcement coming tomorrow! Stay tuned ğŸ‘€ #Innovation #AI",
                    "likes": 156,
                    "retweets": 34,
                    "replies": 12
                },
                {
                    "date": (datetime.now() - timedelta(days=4)).isoformat(),
                    "content": "Proud to partner with @Microsoft Azure for our cloud infrastructure!",
                    "likes": 203,
                    "retweets": 45,
                    "replies": 18
                }
            ],
            "mentions": {
                "positive": 78,
                "neutral": 156,
                "negative": 12,
                "total_last_30_days": 246
            }
        }
    
    async def _analyze_sentiment(self, company_name: str) -> Dict[str, Any]:
        """Analyze overall social media sentiment"""
        await asyncio.sleep(0.3)
        
        return {
            "overall_sentiment": "Positive",
            "sentiment_score": 0.72,  # -1 to 1 scale
            "sentiment_breakdown": {
                "positive": 68,
                "neutral": 25,
                "negative": 7
            },
            "trending_topics": [
                "AI Innovation",
                "Cloud Partnership",
                "Market Expansion",
                "Product Launch",
                "Hiring"
            ],
            "brand_health": "Strong - Positive sentiment with active engagement",
            "competitor_comparison": "Above average in social engagement"
        }
    
    def _generate_insights(self, data: Dict[str, Any]) -> List[str]:
        """Generate social media insights"""
        insights = []
        
        linkedin = data.get("linkedin", {})
        sentiment = data.get("sentiment", {})
        twitter = data.get("twitter", {})
        
        insights.append(f"ğŸ“± Strong social presence: Active on LinkedIn (4.2% engagement) and Twitter")
        insights.append("ğŸ˜Š Positive brand sentiment: 72% sentiment score with 68% positive mentions")
        insights.append("ğŸ”¥ Recent activity spike: Announcement and product launch driving engagement")
        insights.append("ğŸ‘¥ Aggressive hiring: 45 open positions indicates growth phase")
        insights.append("ğŸŒŸ Verified social accounts with engaged follower base")
        insights.append("ğŸ’¡ Trending topics: AI Innovation, Cloud, Market Expansion - align your pitch!")
        
        return insights
